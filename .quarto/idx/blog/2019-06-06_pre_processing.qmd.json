{"title":"Using the recipes package for easy pre-processing","markdown":{"yaml":{"title":"Using the recipes package for easy pre-processing","author":"Rebecca Barter","format":{"html":{"toc":true,"toc-location":"left"}},"categories":["R","workflow","machine learning"],"date":"2019-06-06","description":"Having to apply the same pre-processing steps to training, testing and validation data to do some machine learning can be surprisingly frustrating. But thanks to the recipes R package, it's now super-duper easy. Instead of having five functions and maybe hundreds of lines of code, you can preprocess multiple datasets using a single 'recipe' in fewer than 10 lines of code."},"headingText":"The fundamentals of pre-processing your data using recipes","containsRefs":false,"markdown":"\n\nPre-processing data in R used to be the bane of my existence. For something that should be fairly straightforward, it often really wasn't. Often my frustrations stemmed from simple things such as factor variables having different levels in the training data and test data, or a variable having missing values in the test data but not in the training data. I'd write a function that would pre-process the training data, and when I'd try to apply it to the test data, R would cry and yell and just be generally unpleasant.\n\nThankfully most of the pain of pre-processing is now in the past thanks to the [recipes](https://tidymodels.github.io/recipes/) R package that is a part of the new \"tidymodels\" package ecosystem (which, I guess is supposed to be equivalent to the data-focused \"tidyverse\" package ecosystem that includes dplyr, tidyr, and other super awesome packages like that). Recipes was developed by Max Kuhn and Hadley Wickham.\n\n<!-- Those who have ever seen Hadley Wickham give a talk will know that baking and data are inherently related (see photo below).  -->\n\n<!-- ```{r echo = FALSE, fig.align=\"center\", fig.cap = \"A photo I took at an R Ladies SF meetup of Hadley's cupcake recipes.\"} -->\n\n<!-- knitr::include_graphics(\"/img/recipes/hadley_cupcakes.jpg\") -->\n\n<!-- ``` -->\n\nSo let's get baking!\n\n\nCreating a recipe has four steps:\n\n1.  **Get the ingredients** (`recipe()`): specify the response variable and predictor variables\n\n2.  **Write the recipe** (`step_zzz()`): define the pre-processing steps, such as imputation, creating dummy variables, scaling, and more\n\n3.  **Prepare the recipe** (`prep()`): provide a dataset to base each step on (e.g. if one of the steps is to remove variables that only have one unique value, then you need to give it a dataset so it can decide which variables satisfy this criteria to ensure that it is doing the same thing to every dataset you apply it to)\n\n4.  **Bake the recipe** (`bake()`): apply the pre-processing steps to your datasets\n\nIn this blog post I'll walk you through these three steps, touching on the wide range of things that recipes can do, while hopefully convincing you that recipes makes life really easy and that you should use it next time you need to do some pre-processing.\n\n## A simple example: cupcakes or muffins?\n\nTo keep things in the theme, I'm going to use a dataset from [Alice Zhao's git repo](https://github.com/adashofdata) that I found when I typed \"cupcake dataset\" into Google. Our goal will be to classify recipes as either cupcakes or muffins based on the quantities used for each of the ingredients. So perhaps we will learn two things today: (1) how to use the recipes package, and (2) the difference between cupcakes and muffins.\n\n```{r, message=FALSE, warning=FALSE}\n# set up so that all variables of tibbles are printed\noptions(dplyr.width = Inf)\n# load useful libraries\nlibrary(tidyverse)\nlibrary(recipes) # could also load the tidymodels package\n# load in the data\nmuffin_cupcake_data_orig <- read_csv(\"https://raw.githubusercontent.com/adashofdata/muffin-cupcake/master/recipes_muffins_cupcakes.csv\")\n# look at data\nmuffin_cupcake_data_orig\n```\n\nSince the space in the column name `Baking Powder` is going to really annoy me, I'm going to do a quick clean where I convert all of the column names to lower case and replace the space with an underscore.\n\nAs a side note, I've started naming all of my temporary function arguments (lambda functions?) with a period preceding the name. I find it makes it a lot easier to read. As another side note, if you've never seen the `rename_all()` function before, check out my [blog post](http://www.rebeccabarter.com/blog/2019-01-23_scoped-verbs/) on scoped verbs!\n\n```{r}\nmuffin_cupcake_data <- muffin_cupcake_data_orig %>%\n  # rename all columns \n  rename_all(function(.name) {\n    .name %>% \n      # replace all names with the lowercase versions\n      tolower %>%\n      # replace all spaces with underscores\n      str_replace(\" \", \"_\")\n    })\n# check that this did what I wanted\nmuffin_cupcake_data\n```\n\nSince recipes does a lot of useful stuff for categorical variables as well as with missing values, I'm going to modify the data a little bit so that it's a bit more interesting (for educational purposes only - don't ever actually modify your data so it's more interesting, in science that's called \"fraud\", and fraud is bad).\n\n```{r}\n# add an additional ingredients column that is categorical\nmuffin_cupcake_data <- muffin_cupcake_data %>%\n  mutate(additional_ingredients = c(\"fruit\", \n                                    \"fruit\", \n                                    \"none\", \n                                    \"nuts\", \n                                    \"fruit\", \n                                    \"fruit\", \n                                    \"nuts\", \n                                    \"none\", \n                                    \"none\", \n                                    \"nuts\",\n                                    \"icing\",\n                                    \"icing\",\n                                    \"fruit\",\n                                    \"none\",\n                                    \"fruit\",\n                                    \"icing\",\n                                    \"none\",\n                                    \"fruit\",\n                                    \"icing\",\n                                    \"icing\"))\n# add some random missing values here and there just for fun\nset.seed(26738)\nmuffin_cupcake_data <- muffin_cupcake_data %>%\n  # only add missing values to numeric columns\n  mutate_if(is.numeric,\n            function(x) {\n              # randomly decide if 0, 2, or 3 values will be missing from each column\n              n_missing <- sample(0:3, 1)\n              # replace n_missing randomly selected values from each column with NA\n              x[sample(1:20, n_missing)] <- NA\n              return(x)\n              })\nmuffin_cupcake_data\n```\n\nFinally, I'm going to split my data into training and test sets, so that you can see how nicely our recipe can be applied to multiple data frames.\n\n```{r, message=FALSE}\nlibrary(rsample)\nmuffin_cupcake_split <- initial_split(muffin_cupcake_data)\nmuffin_cupcake_train <- training(muffin_cupcake_split)\nmuffin_cupcake_test <- testing(muffin_cupcake_split)\nrm(muffin_cupcake_data)\n```\n\nOur training data is\n\n```{r}\nmuffin_cupcake_train\n```\n\nand our testing data is\n\n```{r}\nmuffin_cupcake_test\n```\n\n## Writing and applying the recipe\n\nNow that we've set up our data, we're ready to write some recipes and do some baking! The first thing we need to do is get the ingredients. We can use formula notation within the `recipe()` function to do this: the thing we're trying to predict is the variable to the left of the `~`, and the predictor variables are the things to the right of it (Since I'm including all of my variables, I could have written `type ~ .`).\n\n```{r}\n# define the recipe (it looks a lot like applying the lm function)\nmodel_recipe <- recipe(type ~ flour + milk + sugar + butter + egg + \n                         baking_powder + vanilla + salt + additional_ingredients, \n                       data = muffin_cupcake_train)\n```\n\nIf we print a summary of the `model_recipe` object, it just shows us the variables we've specified, their type, and whether they're a predictor or an outcome.\n\n```{r}\nsummary(model_recipe)\n```\n\n### Writing the recipe steps\n\nSo now we have our ingredients, we are ready to write the recipe (i.e. describe our pre-processing steps). We write the recipe one step at a time. We have many steps to choose from, including:\n\n-   `step_dummy()`: creating dummy variables from categorical variables.\n\n-   `step_zzzimpute()`: where instead of \"`zzz`\" it is the name of a method, such as `step_knnimpute()`, `step_meanimpute()`, `step_modeimpute()`. I find that the fancier imputation methods are reeeeally slow for decently large datasets, so I would probably do this step outside of the recipes package unless you just want to do a quick mean or mode impute (which, to be honest, I often do).\n\n-   `step_scale()`: normalize to have a standard deviation of 1.\n\n-   `step_center()`: center to have a mean of 0.\n\n-   `step_range()`: normalize numeric data to be within a pre-defined range of values.\n\n-   `step_pca()`: create principal component variables from your data.\n\n-   `step_nzv()`: remove variables that have (or almost have) the same value for every data point.\n\nYou can also create your own step (which I've never felt the need to do, but the details of which can be found here https://tidymodels.github.io/recipes/articles/Custom_Steps.html).\n\nIn each step, you need to specify which variables you want to apply it to. There are many ways to do this:\n\n1.  Specifying the variable name(s) as the first argument\n\n2.  Standard dplyr selectors:\n\n    -   `everything()` applies the step to all columns,\n\n    -   `contains()` allows you to specify column names that contain a specific string,\n\n    -   `starts_with()` allows you to specify column names that start with a sepcific string,\n\n    -   etc\n\n3.  Functions that specify the role of the variables:\n\n    -   `all_predictors()` applies the step to the predictor variables only\n\n    -   `all_outcomes()` applies the step to the outcome variable(s) only\n\n4.  Functions that specify the type of the variables:\n\n    -   `all_nominal()` applies the step to all variables that are nominal (categorical)\n\n    -   `all_numeric()` applies the step to all variables that are numeric\n\nTo ignore a specific column, you can specify it's name with a negative sign as a variable (just like you would in `select()`)\n\n```{r}\n# define the steps we want to apply\nmodel_recipe_steps <- model_recipe %>% \n  # mean impute numeric variables\n  step_impute_mean(all_numeric()) %>%\n  # convert the additional ingredients variable to dummy variables\n  step_dummy(additional_ingredients) %>%\n  # rescale all numeric variables except for vanilla, salt and baking powder to lie between 0 and 1\n  step_range(all_numeric(), min = 0, max = 1, -vanilla, -salt, -baking_powder) %>%\n  # remove predictor variables that are almost the same for every entry\n  step_nzv(all_predictors()) \n```\n\n```{r}\nmodel_recipe_steps\n```\n\nNote that the order in which you apply the steps does matter to some extent. The recommended ordering ([taken from here](https://tidymodels.github.io/recipes/articles/Ordering.html)) is\n\n1.  Impute\n\n2.  Individual transformations for skewness and other issues\n\n3.  Discretize (if needed and if you have no other choice)\n\n4.  Create dummy variables\n\n5.  Create interactions\n\n6.  Normalization steps (center, scale, range, etc)\n\n7.  Multivariate transformation (e.g. PCA, spatial sign, etc)\n\n### Preparing the recipe\n\nNext, we need to provide a dataset on which to base the pre-processing steps. This allows the same recipe to be applied to multiple datasets.\n\n```{r, warning=FALSE}\nprepped_recipe <- prep(model_recipe_steps, training = muffin_cupcake_train)\n```\n\n```{r}\nprepped_recipe\n```\n\n### Bake the recipe\n\nNext, you apply your recipe to your datasets.\n\nSo what did our recipe do?\n\n-   `step_meanimpute(all_numeric())` imputed all of the missing values with the mean value for that variable\n\n-   `step_dummy(additional_ingredients)` converted the `additional_ingredients` into three dummy variables corresponding to three of the four levels of the original variable\n\n-   `step_range(all_numeric(), min = 0, max = 1, -vanilla, -salt, -baking_powder)` converted the range of all of the numeric variables except for those specified to lie between 0 and 1\n\n-   `step_nzv(all_predictors())` removed the `salt` variable since it was 0 across all rows (except where it was missing)\n\n```{r, warning=FALSE}\nmuffin_cupcake_train_preprocessed <- bake(prepped_recipe, muffin_cupcake_train) \nmuffin_cupcake_train_preprocessed\n```\n\n```{r, warning=FALSE}\nmuffin_cupcake_test_preprocessed <- bake(prepped_recipe, muffin_cupcake_test)\nmuffin_cupcake_test_preprocessed\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"2019-06-06_pre_processing.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.280","theme":"flatly","title-block-banner":true,"title":"Using the recipes package for easy pre-processing","author":"Rebecca Barter","categories":["R","workflow","machine learning"],"date":"2019-06-06","description":"Having to apply the same pre-processing steps to training, testing and validation data to do some machine learning can be surprisingly frustrating. But thanks to the recipes R package, it's now super-duper easy. Instead of having five functions and maybe hundreds of lines of code, you can preprocess multiple datasets using a single 'recipe' in fewer than 10 lines of code.","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}}}