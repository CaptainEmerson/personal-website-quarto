{
  "hash": "8645526e788b6856f9c572ba07bad3de",
  "result": {
    "markdown": "---\ntitle: 'The four \"C\"s for assessing data usefulness'\nauthor: \"Rebecca Barter\"\nformat:\n  html:\n    toc: true\n    toc-location: left\ncategories: [data science, data, data usefulness]\ndate: 2023-04-03\nimage: img/data_usefulness/four_c.jpg\ndescription: \"\"\ndraft: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n![](img/data_usefulness/four_c.jpg){fig-alt='A logo for the data usefulness'}\n\n# What is \"data usefulness\"?\n\nEvery data science project starts with a real-world question and a dataset that can (hopefully!) be used to find some insights that answer the question. But all datasets are not made equal, and the ability of your particular dataset to lead us to a reliable and trustworthy answer depends not just on your data analysis skills, but also on the *usefulness* of the data that you're working with. \n\n\"*Data usefulness*\" is a proxy for how well the data reflects the underlying reality it is intended to represent as well as how easy it is to work with. Data usefulness should always be evaluated in the context of the particular problem that you're trying to solve or question you're trying to answer. After all, if your data is not reflecting reality, or isn't relevant to the problem you're trying to solve, then it's not going to be of much use now, is it?\n\nExamples of data that has low usefulness include data whose values *don't accurately reflect* the real-world quantities they are supposed to capture (e.g., measuring the temperature with a broken thermometer), data that is *missing relevant* data points (e.g., a \"public opinion\" survey that was only taken by one your own followers on social media), data that is *inconsistent* (e.g., state being recorded in inconsistent ways, such as \"California\", \"CA\", \"Cali\"), and data that is *outdated* (e.g., using polls from 2023 to predict the outcome of an election in 2024). While the inconsistent formatting is often easy to fix, the other issues aren't.\n\nIn this blog post, I will introduce the **four \"C\"s** for assessing data quality. The *four \"C\"s* are:\n\n1. **Correct**ness: Are the values in the data *correct*, i.e., are they accurately reflecting the real-world quantities they were designed to capture? \n\n1. **Complete**ness: Does the data contain all of the relevant information needed to answer your question?\n\n1. **Consist**ency: Was the data collected and formatted in a consistent way?\n\n1. **Currency**: Is the data up-to-date and relevant to the situation that you plan to apply it to? And are the observations in your data reflective of the population of interest?\n\nThese measures are more *qualitative* than they are *quantitative*, but they can be really helpful for giving you a sense of your data's potential to provide insights for your real-world problem.\n\n\n# The four \"C\"s for assessing data quality\n\nBy way of an example, let's assess the usefulness of the CDC's [NHANES survey data](https://www.cdc.gov/nchs/nhanes/index.htm) for answering the question of \"*is a relationship between inactivity and depression?*\". If you're interested, the specific version of the data that I'm using can be downloaded from [Kaggle](https://www.kaggle.com/datasets/cdc/national-health-and-nutrition-examination-survey). \n\n\n## Correctness\n\n*Correctness is a measure of whether the values reported in the data are an accurate reflection of the real-world quantity they are designed to measure.*\n\nLet's focus on the `PAD680` variable from the `questionnaire.csv` file in the NHANES data, which contains the responses to the question of \"*How much time do you usually spend sitting on a typical day?*\" The answers to this question are reported in minutes, and range from 0 to 1200. While there are also encoded options for \"don't know\" (`9999`) and \"refused\" (`7777`), around 30\\% of the values are missing (`NA`). \n\nThe table below shows the distribution of the types of responses for this variable, where we categorize a non-missing value that is less than 1200 as \"reported\". Note that fewer than 1% have a \"don't know\" or \"refused\" response.\n\n\n\n::: {.cell}\n\n:::\n\n\nThe histogram in Figure \\@ref(fig:inactivity-hist) shows the distribution of the participants answers to the question \"*How much time do you usually spend sitting on a typical day?*\" (in minutes), for the participants whose answer was reported in the data. A \n\n\n::: {.cell caption='A histogram showing the distribution of responses to the NHANES question \\'How much time do you usually spend sitting on a typical day?\\', with a ghost column added to convey the number of missing values.'}\n\n```{.r .cell-code}\nquestion |>\n  mutate(missing = is.na(PAD680)) |>\n  mutate(PAD680 = if_else(is.na(PAD680), -200, PAD680)) |>\n  filter(PAD680 < 1200) |>\n  ggplot() +\n  geom_histogram(aes(x = PAD680, fill = missing), col = \"white\", bins = 20) +\n  geom_vline(xintercept = -100, linetype = \"dashed\") +\n  geom_text(aes(x = -200, y = 1500, label = lab), \n            tribble(~x, ~y, ~lab,\n                    -200, 1500, \"Missing values (NA)\"),\n            angle = 90, hjust = \"center\", vjust = \"center\", size = 5, nudge_x = -12.5) +\n  theme_classic() +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_fill_manual(values = c(\"grey20\", \"grey70\"), guide = \"none\") +\n  labs(y = \"Number of responses\", x = \"Answer to the question 'How much time do you usually spend sitting on a typical day?'\") +\n  theme(panel.background = element_rect(fill = \"transparent\", colour = NA),  \n        plot.background = element_rect(fill = \"transparent\", colour = NA))\n```\n\n::: {.cell-output-display}\n![](2023-03-31-data_usefulness_files/figure-html/inactivity-hist-1.png){width=672}\n:::\n:::\n\n\n\n**How well do you think this variable (`PAD680`) is reflecting reality?** \n\nTo answer this question, we need to first ask what is this variable trying to capture? The question being asked is \"How much time do you usually spend sitting on a typical day?\", so clearly this variable is trying to capture is the amount of time each person included in the dataset spends sitting in a typical day (note that the question specifically says that this should not include time sleeping).\n\nLet's start with the 30% of values that are missing. Do you think that these values are reflecting reality? They definitely are *not* reflecting reality: they are not at all capturing the amount of time each person spent sitting in a typical day.  \n\nPresumably these values are missing because the individual didn't have a good estimate of how much time they spent sitting on any given day, but this begs the question of why are these values are recorded as missing, rather than \"refused\" or \"don't know\"? Fewer than 1% of answers were \"refused\" or \"don't know\", which implies a potential inconsistency in the way that the data are being collected by the survey takers. We'll get to consistency below.\n\nOkay, so in this case the missing values aren't reflecting reality, and so are not considered \"correct\", but what about the non-missing values. Do you think that these values are \"correct\" in the sense that they are accurately reflecting the actual amount of time each person in the study spends sitting on a typical day? Since this data was not collected by *observing* how much each person sits on a typical day, and it's really hard to actually guess exactly how much time you spend sitting on a typical day (try it for yourself), these values are, at best, vague ball-park figures that are deeply influenced by flawed self-perception and a fear of being judged on their answer.\n\nIn this case, even the non-missing values are unlikely to be \"correct\". Don't lose all hope yet, however! This doesn't mean that you can't analyze your data, it just means that you need to be careful to remember and communicate that the results are based on self-reported measures of inactivity that are not perfectly accurate reflections of reality, which should serve as a reminder not to take any specific numeric conclusions that you arrive at too seriously (e.g., people who spend more than half of their waking hours sitting are more likely to be depressed). General trends, however, are likely to be . \n\nIf you want to *test* the stability of your conclusions to your data, check out Bin Yu's [*Veridical Data Science*](https://www.pnas.org/doi/10.1073/pnas.1901326117) framework (and keep an eye out for the \"Veridical Data Science\" book written by Bin Yu and myself!) for advice on how to do that.\n\n\n\n\n## Completeness\n\nCompleteness is a measure \n\n## Consistency\n\n## Currency\n\n\n\n# Can data cleaning help?\n\nWhile data cleaning can address consistency (e.g., by reformatting inconsistently recorded data values) correctness to some extent (e.g., by replacing invalid or incorrect values with more correct values when they are known), data cleaning cannot fix a lack of completeness or currency.\n\n",
    "supporting": [
      "2023-03-31-data_usefulness_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}