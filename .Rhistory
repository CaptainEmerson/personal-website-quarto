install.packages("fs")
install.packages("stringr")
library(fs)
library(stringr)
rmd_names <- dir_ls(path = ".", glob = "*.Rmd")
rmd_names
rmd_names <- dir_ls(path = "posts/", glob = "*.Rmd")
rmd_names
rmd_names <- dir_ls(path = "posts/", glob = "*.Rmd")
rmd_names
str_replace(string = rmd_names,
pattern = "Rmd",
replacement = "qmd")
qmd_names <- str_replace(string = rmd_names,
pattern = "Rmd",
replacement = "qmd")
file_move(path = rmd_names,
new_path = qmd_names)
setwd("~/Library/CloudStorage/OneDrive-UniversityofUtah/personal-webiste-quarto")
install.packages("ranger")
knitr::include_graphics("img/tidyverse/tidyverse_all.png")
library(tidyverse)
# to download the data directly:
gapminder_orig <- read.csv("https://raw.githubusercontent.com/swcarpentry/r-novice-gapminder/gh-pages/_episodes_rmd/data/gapminder-FiveYearData.csv")
# define a copy of the original dataset that we will clean and play with
gapminder <- gapminder_orig
knitr::include_graphics("img/tidyverse/tidyr.jpg")
long <- gapminder %>%
filter(country %in% c("Australia", "United States", "Canada"), year > 1990) %>%
select(country, year, lifeExp)
long
long %>% mutate(country = paste0(country, "_lifeExp")) %>%
spread(key = country,
value = lifeExp)
gapminder_sample_long <- gapminder %>%
filter(country %in% c("Australia", "United States", "Canada"), year > 1990) %>%
select(country, year, lifeExp)
gapminder_sample_long
gapminder_sample_wide <- gapminder_sample_long %>%
spread(key = country, value = lifeExp)
gapminder_sample_wide
gapminder_sample_wide
gapminder_sample_wide %>%
gather(key = country_var, value = lifeExp_var)
gapminder_sample_wide %>%
gather(key = country_var, value = lifeExp_var, -year)
gapminder_sample_united <- gapminder_sample_long %>%
unite("countryyear", country, year, sep = "_")
gapminder_sample_united
gapminder_sample_united %>%
separate(countryyear, c("country", "year"), sep = "_")
knitr::include_graphics("img/tidyverse/purrr.jpg")
lapply(c(1, 4, 7), function(number) {
return(number + 10)
})
sapply(c(1, 4, 7), function(number) {
return(number + 10)
})
library(purrr)
map(c(1, 4, 7), function(number) {
return(number + 10)
})
map_dbl(c(1, 4, 7), function(number) {
return(number + 10)
})
map_chr(c(1, 4, 7), function(number) {
return(number + 10)
})
map_df(c(1, 4, 7), function(number) {
return(data.frame(old_number = number,
new_number = number + 10))
})
knitr::include_graphics("img/tidyverse/readr.png")
parse_number(c("$1,234.5", "$12.45", "99%"))
parse_datetime("2010-10-01 21:45")
knitr::include_graphics("img/tidyverse/tibble.png")
knitr::include_graphics("img/tidyverse/lubridate.png")
library(lubridate)
mdy("August 2nd 2019")
mdy("8-2-2019")
mdy("8/2/19")
hms("8:45:12")
mdy_hms("March 13th 2019 at 9:02:00")
mdy_hm("03-13-19, 9:02")
mdy("August 2nd 2019") + days(42)
mdy_hms("August 2nd 2019, 1:21:30 pm") - mdy_hms("August 1st 2019, 11:23:33 am")
knitr::include_graphics("img/tidyverse/forcats.png")
# add an additional ingredients column that is categorical
muffin_cupcake_data <- muffin_cupcake_data %>%
mutate(additional_ingredients = c("fruit",
"fruit",
"none",
"nuts",
"fruit",
"fruit",
"nuts",
"none",
"none",
"nuts",
"icing",
"icing",
"fruit",
"none",
"fruit",
"icing",
"none",
"fruit",
"icing",
"icing"))
# add some random missing values here and there just for fun
set.seed(26738)
muffin_cupcake_data <- muffin_cupcake_data %>%
# only add missing values to numeric columns
mutate_if(is.numeric,
function(x) {
# randomly decide if 0, 2, or 3 values will be missing from each column
n_missing <- sample(0:3, 8, replace = TRUE)
# replace n_missing randomly selected values from each column with NA
x[sample(1:20, n_missing)] <- NA
return(x)
})
# add an additional ingredients column that is categorical
muffin_cupcake_data <- muffin_cupcake_data %>%
mutate(additional_ingredients = c("fruit",
"fruit",
"none",
"nuts",
"fruit",
"fruit",
"nuts",
"none",
"none",
"nuts",
"icing",
"icing",
"fruit",
"none",
"fruit",
"icing",
"none",
"fruit",
"icing",
"icing"))
# set up so that all variables of tibbles are printed
options(dplyr.width = Inf)
# load useful libraries
library(tidyverse)
library(recipes) # could also load the tidymodels package
# load in the data
muffin_cupcake_data_orig <- read_csv("https://raw.githubusercontent.com/adashofdata/muffin-cupcake/master/recipes_muffins_cupcakes.csv")
# look at data
muffin_cupcake_data_orig
muffin_cupcake_data <- muffin_cupcake_data_orig %>%
# rename all columns
rename_all(function(.name) {
.name %>%
# replace all names with the lowercase versions
tolower %>%
# replace all spaces with underscores
str_replace(" ", "_")
})
# check that this did what I wanted
muffin_cupcake_data
# add an additional ingredients column that is categorical
muffin_cupcake_data <- muffin_cupcake_data %>%
mutate(additional_ingredients = c("fruit",
"fruit",
"none",
"nuts",
"fruit",
"fruit",
"nuts",
"none",
"none",
"nuts",
"icing",
"icing",
"fruit",
"none",
"fruit",
"icing",
"none",
"fruit",
"icing",
"icing"))
# add some random missing values here and there just for fun
set.seed(26738)
muffin_cupcake_data <- muffin_cupcake_data %>%
# only add missing values to numeric columns
mutate_if(is.numeric,
function(x) {
# randomly decide if 0, 2, or 3 values will be missing from each column
n_missing <- sample(0:3, 8, replace = TRUE)
# replace n_missing randomly selected values from each column with NA
x[sample(1:20, n_missing)] <- NA
return(x)
})
0:3
sample(0:3, 8, replace = TRUE)
n_missing
# randomly decide if 0, 2, or 3 values will be missing from each column
n_missing <- sample(0:3, 8, replace = TRUE)
n_missing
muffin_cupcake_data
muffin_cupcake_data
sample(1:20, n_missing)
# add some random missing values here and there just for fun
set.seed(26738)
muffin_cupcake_data <- muffin_cupcake_data %>%
# only add missing values to numeric columns
mutate_if(is.numeric,
function(x) {
# randomly decide if 0, 2, or 3 values will be missing from each column
n_missing <- sample(0:3, 1)
# replace n_missing randomly selected values from each column with NA
x[sample(1:20, n_missing)] <- NA
return(x)
})
muffin_cupcake_data
muffin_cupcake_data
muffin_cupcake_data
# add an additional ingredients column that is categorical
muffin_cupcake_data <- muffin_cupcake_data %>%
mutate(additional_ingredients = c("fruit",
"fruit",
"none",
"nuts",
"fruit",
"fruit",
"nuts",
"none",
"none",
"nuts",
"icing",
"icing",
"fruit",
"none",
"fruit",
"icing",
"none",
"fruit",
"icing",
"icing"))
# add some random missing values here and there just for fun
set.seed(26738)
muffin_cupcake_data <- muffin_cupcake_data %>%
# only add missing values to numeric columns
mutate_if(is.numeric,
function(x) {
# randomly decide if 0, 2, or 3 values will be missing from each column
n_missing <- sample(0:3, 1)
# replace n_missing randomly selected values from each column with NA
x[sample(1:20, n_missing)] <- NA
return(x)
})
muffin_cupcake_data
# load in packages
library(caret)
library(ranger)
library(tidyverse)
library(e1071)
# load in abalone dataset
abalone_data <- read.table("data/abalone.data", sep = ",")
# load in column names
colnames(abalone_data) <- c("sex", "length", "diameter", "height",
"whole.weight", "shucked.weight",
"viscera.weight", "shell.weight", "age")
# add a logical variable for "old" (age > 10)
abalone_data <- abalone_data %>%
mutate(old = age > 10) %>%
# remove the "age" variable
select(-age)
# split into training and testing
set.seed(23489)
train_index <- sample(1:nrow(abalone_data), 0.9 * nrow(abalone_data))
abalone_train <- abalone_data[train_index, ]
abalone_test <- abalone_data[-train_index, ]
# remove the original dataset
rm(abalone_data)
# view the first 6 rows of the training data
head(abalone_train)
dim(abalone_train)
# fit a random forest model (using ranger)
rf_fit <- train(as.factor(old) ~ .,
data = abalone_train,
method = "ranger")
# load in packages
library(caret)
library(ranger)
library(tidyverse)
library(e1071)
# load in abalone dataset
abalone_data <- read.table("data/abalone.data", sep = ",")
# load in column names
colnames(abalone_data) <- c("sex", "length", "diameter", "height",
"whole.weight", "shucked.weight",
"viscera.weight", "shell.weight", "age")
# add a logical variable for "old" (age > 10)
abalone_data <- abalone_data %>%
mutate(old = age > 10) %>%
# remove the "age" variable
select(-age)
# split into training and testing
set.seed(23489)
train_index <- sample(1:nrow(abalone_data), 0.9 * nrow(abalone_data))
abalone_train <- abalone_data[train_index, ]
abalone_test <- abalone_data[-train_index, ]
# remove the original dataset
rm(abalone_data)
# view the first 6 rows of the training data
head(abalone_train)
dim(abalone_train)
# fit a random forest model (using ranger)
rf_fit <- train(as.factor(old) ~ .,
data = abalone_train,
method = "ranger")
rf_fit
# predict the outcome on a test set
abalone_rf_pred <- predict(rf_fit, abalone_test)
# compare predicted outcome and true outcome
confusionMatrix(abalone_rf_pred, as.factor(abalone_test$old))
# center, scale and perform a YeoJohnson transformation
# identify and remove variables with near zero variance
# perform pca
abalone_no_nzv_pca <- preProcess(select(abalone_train, - old),
method = c("center", "scale", "nzv", "pca"))
abalone_no_nzv_pca
# identify which variables were ignored, centered, scaled, etc
abalone_no_nzv_pca$method
# identify the principal components
abalone_no_nzv_pca$rotation
# identify the indices of 10 80% subsamples of the iris data
train_index <- createDataPartition(iris$Species,
p = 0.8,
list = FALSE,
times = 10)
# look at the first 6 indices of each subsample
head(train_index)
# add a madeup grouping variable that groupes each subsequent 5 abalone together
# filter to the first 50 abalone for simplicity
abalone_grouped <- cbind(abalone_train[1:50, ], group = rep(1:10, each = 5))
head(abalone_grouped, 10)
# perform grouped K means
group_folds <- groupKFold(abalone_grouped$group, k = 10)
group_folds
set.seed(998)
# create a testing and training set
in_training <- createDataPartition(abalone_train$old, p = .75, list = FALSE)
training <- abalone_train[ in_training,]
testing  <- abalone_train[-in_training,]
# specify that the resampling method is
fit_control <- trainControl(## 10-fold CV
method = "cv",
number = 10)
# run a random forest model
set.seed(825)
rf_fit <- train(as.factor(old) ~ .,
data = abalone_train,
method = "ranger",
trControl = fit_control)
rf_fit
# specify that the resampling method is
group_fit_control <- trainControl(## use grouped CV folds
index = group_folds,
method = "cv")
set.seed(825)
rf_fit <- train(as.factor(old) ~ .,
data = select(abalone_grouped, - group),
method = "ranger",
trControl = group_fit_control)
rf_fit
# define a grid of parameter options to try
rf_grid <- expand.grid(mtry = c(2, 3, 4, 5),
splitrule = c("gini", "extratrees"),
min.node.size = c(1, 3, 5))
rf_grid
# re-fit the model with the parameter grid
rf_fit <- train(as.factor(old) ~ .,
data = select(abalone_grouped, - group),
method = "ranger",
trControl = group_fit_control,
# provide a grid of parameters
tuneGrid = rf_grid)
rf_fit
quarto publish
